"""
è‚¡ç¥¨æ—¥çº¿æ•°æ®è·å–ä»»åŠ¡
ä» Tushare è·å–æ—¥çº¿æ•°æ®å¹¶åŒæ­¥åˆ°æœ¬åœ°æ•°æ®åº“
"""
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import time

import tushare as ts
import httpx
import pandas as pd

from app.core.config import settings
from app.utils.logger import logger


class StockDailyFetcher:
    """è‚¡ç¥¨æ—¥çº¿æ•°æ®è·å–å™¨"""

    def __init__(self):
        """åˆå§‹åŒ–"""
        self.last_fetch_time: Optional[datetime] = None
        self.api_base_url = f"http://{settings.stock_api_host}:{settings.stock_api_port}/api"
        self.batch_size = 1000
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {settings.stock_api_token}"
        }
        # åˆå§‹åŒ– tushare pro
        self.tushare_token = "347ae3b92b9a97638f155512bc599767558b94c3dcb47f5abd058b95"
        ts.set_token(self.tushare_token)
        self.pro = ts.pro_api()

        # é¢‘ç‡é™åˆ¶æ§åˆ¶
        self.request_count = 0  # å½“å‰åˆ†é’Ÿå†…çš„è¯·æ±‚è®¡æ•°
        self.request_limit = 45  # æ¯åˆ†é’Ÿæœ€å¤§è¯·æ±‚æ¬¡æ•°
        self.minute_start_time = None  # ç¬¬ä¸€æ¬¡è¯·æ±‚çš„æ—¶é—´ï¼Œç”¨äºè®¡ç®—ä¸€åˆ†é’Ÿå‘¨æœŸ
        self.max_retries = 3  # å•æ¬¡è¯·æ±‚æœ€å¤§é‡è¯•æ¬¡æ•°
        self.retry_delay = 5  # æ¯æ¬¡é‡è¯•ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
        self.final_retry_delay = 60  # ä¸‰æ¬¡å¤±è´¥åçš„æœ€ç»ˆé‡è¯•ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰

    async def sync_stock_daily(self):
        """
        åŒæ­¥è‚¡ç¥¨æ—¥çº¿æ•°æ®
        æ¯å¤©ä¸‹åˆ5:20æ‰§è¡Œä¸€æ¬¡

        æµç¨‹ï¼š
        1. æŸ¥è¯¢æ•°æ®åº“ä¸­æœ€æ–°çš„æ—¥çº¿æ•°æ®æ—¥æœŸ
        2. å¦‚æœæ²¡æœ‰åˆ™ä»1990å¹´å¼€å§‹æŸ¥äº¤æ˜“æ—¥ï¼Œè·å–åˆ°è·ä»Šå¤©æœ€è¿‘çš„ä¸€ä¸ªäº¤æ˜“æ—¥ï¼ˆåŒ…æ‹¬ä»Šå¤©ï¼‰çš„æ‰€æœ‰äº¤æ˜“æ—¥
        3. å¦‚æœæœ‰æœ€æ–°æ—¥æœŸï¼š
           - ä»Šå¤©æ˜¯äº¤æ˜“æ—¥ä¸”è¿”å›çš„æ—¥æœŸæ˜¯ä»Šå¤© â†’ ç›´æ¥ç»“æŸ
           - ä»Šå¤©æ˜¯äº¤æ˜“æ—¥ä¸”è¿”å›çš„æ—¥æœŸæ˜¯å‰ä¸€ä¸ªäº¤æ˜“æ—¥ â†’ åªæŸ¥ä»Šå¤©
           - ä»Šå¤©ä¸æ˜¯äº¤æ˜“æ—¥ â†’ ä»è¿”å›çš„æ—¥æœŸå¼€å§‹æŸ¥åˆ°ä»Šå¤©å‰çš„ä¸€ä¸ªäº¤æ˜“æ—¥
        4. æ‹¿åˆ°æ‰€æœ‰è¦æŸ¥çš„äº¤æ˜“æ—¥åï¼Œå¼€å§‹ä¸€å¤©ä¸€å¤©çš„æŸ¥ Tushareï¼ˆä¸ä¼ è‚¡ç¥¨ä»£ç ï¼‰
        5. ä» Tushare æŸ¥åˆ°æ•°æ®åç›´æ¥è°ƒç”¨åç«¯æ¥å£ä¿å­˜
        """
        logger.info("=" * 80)
        logger.info("å¼€å§‹åŒæ­¥è‚¡ç¥¨æ—¥çº¿æ•°æ®...")
        logger.info(f"æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info("=" * 80)

        try:
            # 1. æŸ¥è¯¢æ•°æ®åº“ä¸­æœ€æ–°çš„æ—¥çº¿æ•°æ®æ—¥æœŸ
            logger.info("ğŸ“Š æ­¥éª¤1: æŸ¥è¯¢æ•°æ®åº“ä¸­æœ€æ–°çš„æ—¥çº¿æ•°æ®æ—¥æœŸ...")
            latest_date = await self._get_latest_daily_date()

            # 2. è·å–äº¤æ˜“æ—¥å†ï¼ˆåˆ°ä»Šå¤©ä¸ºæ­¢ï¼‰
            today = datetime.now().strftime("%Y-%m-%d")
            logger.info("\nğŸ“Š æ­¥éª¤2: è·å–äº¤æ˜“æ—¥å†...")

            if latest_date:
                logger.info(f"âœ“ æ•°æ®åº“ä¸­æœ€æ–°æ—¥çº¿æ•°æ®æ—¥æœŸ: {latest_date}")
                # è·å–ä»æœ€æ–°æ—¥æœŸæ‰€åœ¨å¹´åˆ°ä»Šå¹´çš„äº¤æ˜“æ—¥å†
                start_year = datetime.strptime(latest_date, "%Y-%m-%d").year
                current_year = datetime.now().year
                trade_dates = []
                for year in range(start_year, current_year + 1):
                    logger.info(f"  è·å– {year} å¹´äº¤æ˜“æ—¥å†...")
                    year_dates = await self._get_trade_calendar(year)
                    trade_dates.extend(year_dates)
                    await asyncio.sleep(0.1)
                trade_dates.sort()
            else:
                logger.info("âœ“ æ•°æ®åº“ä¸­æ²¡æœ‰æ—¥çº¿æ•°æ®ï¼Œä»1990å¹´å¼€å§‹æŸ¥è¯¢äº¤æ˜“æ—¥å†")
                # ä»1990å¹´å¼€å§‹æŸ¥è¯¢æ‰€æœ‰äº¤æ˜“æ—¥å†åˆ°ä»Šå¤©
                trade_dates = await self._get_trade_calendar_from_1990()

            if not trade_dates:
                logger.warning("âš ï¸  æœªè·å–åˆ°äº¤æ˜“æ—¥å†æ•°æ®ï¼Œä»»åŠ¡ç»“æŸ")
                return

            # åªä¿ç•™åˆ°ä»Šå¤©ä¸ºæ­¢çš„äº¤æ˜“æ—¥ï¼ˆåŒ…æ‹¬ä»Šå¤©ï¼‰
            trade_dates = [d for d in trade_dates if d <= today]
            logger.info(f"âœ“ å…±è·å– {len(trade_dates)} ä¸ªäº¤æ˜“æ—¥ï¼ˆæˆªæ­¢åˆ°ä»Šå¤©ï¼‰")

            # 3. ç¡®å®šéœ€è¦åŒæ­¥çš„äº¤æ˜“æ—¥æœŸèŒƒå›´
            logger.info("\nğŸ“Š æ­¥éª¤3: ç¡®å®šéœ€è¦åŒæ­¥çš„æ—¥æœŸèŒƒå›´...")

            if latest_date:
                # æ£€æŸ¥ä»Šå¤©æ˜¯å¦æ˜¯äº¤æ˜“æ—¥
                is_today_trading = today in trade_dates

                if is_today_trading:
                    if latest_date == today:
                        # ä»Šå¤©æ˜¯äº¤æ˜“æ—¥ä¸”è¿”å›çš„æ—¥æœŸæ˜¯ä»Šå¤© â†’ ç›´æ¥ç»“æŸ
                        logger.info("âœ“ æœ€æ–°æ•°æ®å·²æ˜¯ä»Šå¤©ï¼Œæ— éœ€åŒæ­¥")
                        return
                    else:
                        # ä»Šå¤©æ˜¯äº¤æ˜“æ—¥ä¸”è¿”å›çš„æ—¥æœŸä¸æ˜¯ä»Šå¤©
                        # æ‰¾åˆ°æœ€æ–°æ—¥æœŸçš„ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥
                        if latest_date in trade_dates:
                            latest_idx = trade_dates.index(latest_date)
                            # è·å–ä»ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥åˆ°ä»Šå¤©çš„æ‰€æœ‰äº¤æ˜“æ—¥
                            dates_to_sync = trade_dates[latest_idx + 1:]
                            dates_to_sync = [d for d in dates_to_sync if d <= today]
                        else:
                            # å¦‚æœæœ€æ–°æ—¥æœŸä¸åœ¨äº¤æ˜“æ—¥åˆ—è¡¨ä¸­ï¼Œä»æœ€æ–°æ—¥æœŸä¹‹åçš„ç¬¬ä¸€ä¸ªäº¤æ˜“æ—¥å¼€å§‹
                            dates_to_sync = [d for d in trade_dates if d > latest_date and d <= today]

                        if not dates_to_sync:
                            logger.info("âœ“ å·²æ˜¯æœ€æ–°æ•°æ®ï¼Œæ— éœ€åŒæ­¥")
                            return
                else:
                    # ä»Šå¤©ä¸æ˜¯äº¤æ˜“æ—¥ â†’ ä»è¿”å›çš„æ—¥æœŸçš„ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥æŸ¥åˆ°ä»Šå¤©å‰çš„ä¸€ä¸ªäº¤æ˜“æ—¥
                    if latest_date in trade_dates:
                        latest_idx = trade_dates.index(latest_date)
                        # è·å–ä»ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥å¼€å§‹çš„æ‰€æœ‰äº¤æ˜“æ—¥ï¼ˆä»Šå¤©ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œæ‰€ä»¥ä¸ä¼šåŒ…å«ä»Šå¤©ï¼‰
                        dates_to_sync = trade_dates[latest_idx + 1:]
                        dates_to_sync = [d for d in dates_to_sync if d < today]
                    else:
                        # å¦‚æœæœ€æ–°æ—¥æœŸä¸åœ¨äº¤æ˜“æ—¥åˆ—è¡¨ä¸­ï¼Œä»æœ€æ–°æ—¥æœŸä¹‹åçš„ç¬¬ä¸€ä¸ªäº¤æ˜“æ—¥å¼€å§‹
                        dates_to_sync = [d for d in trade_dates if d > latest_date and d < today]

                    if not dates_to_sync:
                        logger.info("âœ“ ä»Šå¤©ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œä¸”å·²æ˜¯æœ€æ–°æ•°æ®ï¼Œæ— éœ€åŒæ­¥")
                        return

                logger.info(f"âœ“ éœ€è¦åŒæ­¥ {len(dates_to_sync)} ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®")
                logger.info(f"  èµ·å§‹æ—¥æœŸ: {dates_to_sync[0]}")
                logger.info(f"  ç»“æŸæ—¥æœŸ: {dates_to_sync[-1]}")
            else:
                # ä»1990å¹´ç¬¬ä¸€ä¸ªäº¤æ˜“æ—¥å¼€å§‹åˆ°ä»Šå¤©ï¼ˆæˆ–ä»Šå¤©å‰çš„ä¸€ä¸ªäº¤æ˜“æ—¥ï¼‰
                dates_to_sync = trade_dates
                logger.info(f"âœ“ éœ€è¦åŒæ­¥ {len(dates_to_sync)} ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®ï¼ˆä»1990å¹´å¼€å§‹ï¼‰")
                logger.info(f"  èµ·å§‹æ—¥æœŸ: {dates_to_sync[0]}")
                logger.info(f"  ç»“æŸæ—¥æœŸ: {dates_to_sync[-1]}")

            # 4. é€ä¸ªäº¤æ˜“æ—¥åŒæ­¥æ•°æ®ï¼ˆä¸ä¼ è‚¡ç¥¨ä»£ç ï¼Œç›´æ¥ä»TushareæŒ‰æ—¥æœŸæŸ¥è¯¢ï¼‰
            logger.info("\nğŸ“Š æ­¥éª¤4: å¼€å§‹é€ä¸ªäº¤æ˜“æ—¥ä»TushareåŒæ­¥æ•°æ®...")
            total_dates = len(dates_to_sync)
            success_count = 0
            fail_count = 0

            for idx, trade_date in enumerate(dates_to_sync, 1):
                logger.info(f"\n[{idx}/{total_dates}] æ­£åœ¨åŒæ­¥ {trade_date} çš„æ—¥çº¿æ•°æ®...")

                try:
                    # ä»Tushareè·å–è¯¥äº¤æ˜“æ—¥çš„æ‰€æœ‰è‚¡ç¥¨æ—¥çº¿æ•°æ®ï¼ˆä¸ä¼ è‚¡ç¥¨ä»£ç ï¼‰
                    daily_data = await self._fetch_daily_by_date(trade_date)

                    # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ç»ˆå¤±è´¥ï¼ˆè¿”å›Noneï¼‰
                    if daily_data is None:
                        logger.error(f"âŒ {trade_date} æ•°æ®è·å–æœ€ç»ˆå¤±è´¥ï¼Œä»»åŠ¡ç»“æŸ")
                        logger.info("\n" + "=" * 80)
                        logger.info(f"âœ— è‚¡ç¥¨æ—¥çº¿æ•°æ®åŒæ­¥è¢«ä¸­æ–­ï¼")
                        logger.info(f"  æˆåŠŸ: {success_count}/{idx}")
                        logger.info(f"  å¤±è´¥: {fail_count + 1}/{idx}")
                        logger.info(f"  ä¸­æ–­äº: {trade_date}")
                        logger.info("=" * 80)
                        return

                    if daily_data:
                        # ç›´æ¥ä¿å­˜åˆ°æ•°æ®åº“
                        saved = await self._save_daily_data(daily_data)
                        if saved:
                            success_count += 1
                            logger.info(f"âœ“ {trade_date} æ•°æ®ä¿å­˜æˆåŠŸï¼Œå…± {len(daily_data)} æ¡è®°å½•")
                        else:
                            fail_count += 1
                            logger.error(f"âœ— {trade_date} æ•°æ®ä¿å­˜å¤±è´¥")
                    else:
                        # ç©ºåˆ—è¡¨ï¼Œè¡¨ç¤ºè¯¥æ—¥æœŸæ²¡æœ‰æ•°æ®ï¼ˆéäº¤æ˜“æ—¥æˆ–å…¶ä»–åŸå› ï¼‰
                        logger.warning(f"âš ï¸  {trade_date} æœªè·å–åˆ°æ•°æ®")

                except Exception as e:
                    fail_count += 1
                    logger.error(f"âœ— {trade_date} æ•°æ®åŒæ­¥å¤±è´¥: {str(e)}")
                    continue

            # 5. æ€»ç»“
            logger.info("\n" + "=" * 80)
            logger.info(f"âœ“ è‚¡ç¥¨æ—¥çº¿æ•°æ®åŒæ­¥å®Œæˆï¼")
            logger.info(f"  æˆåŠŸ: {success_count}/{total_dates}")
            logger.info(f"  å¤±è´¥: {fail_count}/{total_dates}")
            logger.info("=" * 80)

            self.last_fetch_time = datetime.now()

        except Exception as e:
            logger.error(f"\nâŒ è‚¡ç¥¨æ—¥çº¿æ•°æ®åŒæ­¥ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}", exc_info=True)
            raise

    async def _get_latest_daily_date(self) -> Optional[str]:
        """
        æŸ¥è¯¢æ•°æ®åº“ä¸­æœ€æ–°çš„æ—¥çº¿æ•°æ®æ—¥æœŸ

        Returns:
            æœ€æ–°æ—¥æœŸå­—ç¬¦ä¸²ï¼ˆæ ¼å¼: YYYY-MM-DDï¼‰ï¼Œå¦‚æœæ²¡æœ‰æ•°æ®åˆ™è¿”å› None
        """
        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.get(
                    f"{self.api_base_url}/stock-daily/latest-date",
                    headers=self.headers
                )
                response.raise_for_status()

                # è§£æ JSON å“åº”
                result = response.json()

                # ä» data å­—æ®µä¸­è·å–æ—¥æœŸæ•°æ®
                latest_date = result.get("data")

                # åˆ¤æ–­æ˜¯å¦ä¸ºæœ‰æ•ˆæ—¥æœŸï¼šdata å¯èƒ½æ˜¯ nullã€ç©ºå­—ç¬¦ä¸²æˆ–æœ‰æ•ˆæ—¥æœŸå­—ç¬¦ä¸²
                if not latest_date or (isinstance(latest_date, str) and latest_date.lower() == "null"):
                    return None

                return latest_date

        except Exception as e:
            logger.error(f"æŸ¥è¯¢æœ€æ–°æ—¥çº¿æ•°æ®æ—¥æœŸå¤±è´¥: {str(e)}")
            return None

    async def _get_trade_calendar(self, year: int) -> List[str]:
        """
        è·å–æŒ‡å®šå¹´ä»½çš„äº¤æ˜“æ—¥å†

        Args:
            year: å¹´ä»½

        Returns:
            äº¤æ˜“æ—¥æœŸåˆ—è¡¨ï¼Œæ ¼å¼: ['2024-01-02', '2024-01-03', ...]
        """
        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.get(
                    f"{self.api_base_url}/trading-calendar/year/{year}",
                    headers=self.headers
                )
                response.raise_for_status()

                result = response.json()
                if result.get("code") == 200:
                    data = result.get("data", [])
                    # æå–æ‰€æœ‰äº¤æ˜“æ—¥ï¼ˆisTradingDay=1ï¼‰çš„æ—¥æœŸ
                    # å­—æ®µåï¼štradeDate, isTradingDay
                    trade_dates = [item["tradeDate"] for item in data if item.get("isTradingDay") == 1]
                    trade_dates.sort()
                    return trade_dates
                else:
                    logger.error(f"è·å–{year}å¹´äº¤æ˜“æ—¥å†å¤±è´¥: {result.get('message')}")
                    return []

        except Exception as e:
            logger.error(f"è·å–{year}å¹´äº¤æ˜“æ—¥å†å¤±è´¥: {str(e)}")
            return []

    async def _get_trade_calendar_from_1990(self) -> List[str]:
        """
        è·å–ä»1990å¹´åˆ°ä»Šå¹´çš„æ‰€æœ‰äº¤æ˜“æ—¥å†

        Returns:
            äº¤æ˜“æ—¥æœŸåˆ—è¡¨ï¼Œæ ¼å¼: ['1990-12-19', '1990-12-20', ...]
        """
        current_year = datetime.now().year
        all_trade_dates = []

        for year in range(1990, current_year + 1):
            logger.info(f"  è·å– {year} å¹´äº¤æ˜“æ—¥å†...")
            trade_dates = await self._get_trade_calendar(year)
            all_trade_dates.extend(trade_dates)
            await asyncio.sleep(0.1)  # é¿å…è¯·æ±‚è¿‡å¿«

        all_trade_dates.sort()
        logger.info(f"âœ“ å…±è·å– {len(all_trade_dates)} ä¸ªäº¤æ˜“æ—¥")
        return all_trade_dates

    async def _get_all_stock_codes(self) -> List[str]:
        """
        è·å–æ‰€æœ‰è‚¡ç¥¨ä»£ç 

        Returns:
            è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œæ ¼å¼: ['000001.SZ', '000002.SZ', ...]
        """
        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.get(
                    f"{self.api_base_url}/stock/codes",
                    headers=self.headers
                )
                response.raise_for_status()

                result = response.json()
                if result.get("code") == 200:
                    codes = result.get("data", [])
                    return codes
                else:
                    logger.error(f"è·å–è‚¡ç¥¨ä»£ç åˆ—è¡¨å¤±è´¥: {result.get('message')}")
                    return []

        except Exception as e:
            logger.error(f"è·å–è‚¡ç¥¨ä»£ç åˆ—è¡¨å¤±è´¥: {str(e)}")
            return []

    async def _fetch_daily_by_date(self, trade_date: str) -> List[Dict]:
        """
        è·å–æŒ‡å®šäº¤æ˜“æ—¥æ‰€æœ‰è‚¡ç¥¨çš„æ—¥çº¿æ•°æ®ï¼ˆä¸ä¼ è‚¡ç¥¨ä»£ç ï¼‰

        å¸¦é‡è¯•æœºåˆ¶ï¼š
        - å¤±è´¥æ—¶ç­‰å¾…5ç§’é‡è¯•ï¼Œæœ€å¤šé‡è¯•3æ¬¡
        - 3æ¬¡éƒ½å¤±è´¥åç­‰å¾…1åˆ†é’Ÿå†é‡è¯•ä¸€æ¬¡
        - å¦‚æœæœ€ç»ˆé‡è¯•è¿˜æ˜¯å¤±è´¥ï¼Œè¿”å›Noneå¹¶ç»“æŸä»»åŠ¡

        Args:
            trade_date: äº¤æ˜“æ—¥æœŸï¼Œæ ¼å¼: YYYY-MM-DD

        Returns:
            æ—¥çº¿æ•°æ®åˆ—è¡¨ï¼Œå¦‚æœæœ€ç»ˆå¤±è´¥è¿”å› Noneï¼ˆåŒºåˆ«äºç©ºåˆ—è¡¨ï¼‰
        """
        # è½¬æ¢æ—¥æœŸæ ¼å¼ YYYY-MM-DD -> YYYYMMDD
        date_str = trade_date.replace("-", "")

        # ç¬¬ä¸€é˜¶æ®µï¼šå°è¯•3æ¬¡ï¼Œæ¯æ¬¡å¤±è´¥ç­‰å¾…5ç§’
        for attempt in range(1, self.max_retries + 1):
            try:
                # æ£€æŸ¥å¹¶æ§åˆ¶é¢‘ç‡
                await self._check_rate_limit()

                # è°ƒç”¨ Tushare æ¥å£è·å–è¯¥æ—¥æ‰€æœ‰è‚¡ç¥¨çš„æ—¥çº¿æ•°æ®ï¼ˆä¸ä¼  ts_codeï¼‰
                df = self.pro.daily(trade_date=date_str)

                # è¯·æ±‚æˆåŠŸï¼Œå¢åŠ è®¡æ•°
                self.request_count += 1

                if df is None or df.empty:
                    logger.warning(f"  {trade_date} æœªè·å–åˆ°æ•°æ®")
                    return []

                # è½¬æ¢æ•°æ®æ ¼å¼
                all_daily_data = []
                for _, row in df.iterrows():
                    daily_item = {
                        "stockCode": row["ts_code"],
                        "tradeDate": f"{row['trade_date'][:4]}-{row['trade_date'][4:6]}-{row['trade_date'][6:8]}",
                        "openPrice": float(row["open"]) if pd.notna(row["open"]) else None,
                        "highPrice": float(row["high"]) if pd.notna(row["high"]) else None,
                        "lowPrice": float(row["low"]) if pd.notna(row["low"]) else None,
                        "closePrice": float(row["close"]) if pd.notna(row["close"]) else None,
                        "preClose": float(row["pre_close"]) if pd.notna(row["pre_close"]) else None,
                        "changeAmount": float(row["change"]) if pd.notna(row["change"]) else None,
                        "pctChange": float(row["pct_chg"]) if pd.notna(row["pct_chg"]) else None,
                        "volume": float(row["vol"]) if pd.notna(row["vol"]) else None,
                        "amount": float(row["amount"]) if pd.notna(row["amount"]) else None
                    }
                    all_daily_data.append(daily_item)

                logger.info(f"  ä»Tushareè·å–åˆ° {len(all_daily_data)} æ¡è®°å½•")
                return all_daily_data

            except Exception as e:
                logger.error(f"  ä»Tushareè·å– {trade_date} æ•°æ®å¤±è´¥ (å°è¯• {attempt}/{self.max_retries}): {str(e)}")

                if attempt < self.max_retries:
                    logger.info(f"  ç­‰å¾… {self.retry_delay} ç§’åé‡è¯•...")
                    await asyncio.sleep(self.retry_delay)
                else:
                    # 3æ¬¡éƒ½å¤±è´¥äº†ï¼Œè¿›å…¥æœ€ç»ˆé‡è¯•é˜¶æ®µ
                    logger.warning(f"  {trade_date} å·²é‡è¯• {self.max_retries} æ¬¡å¤±è´¥ï¼Œç­‰å¾… {self.final_retry_delay} ç§’åè¿›è¡Œæœ€ç»ˆé‡è¯•...")
                    await asyncio.sleep(self.final_retry_delay)

        # ç¬¬äºŒé˜¶æ®µï¼šæœ€ç»ˆé‡è¯•ä¸€æ¬¡
        try:
            logger.info(f"  {trade_date} å¼€å§‹æœ€ç»ˆé‡è¯•...")

            # æ£€æŸ¥å¹¶æ§åˆ¶é¢‘ç‡
            await self._check_rate_limit()

            # è°ƒç”¨ Tushare æ¥å£
            df = self.pro.daily(trade_date=date_str)

            # è¯·æ±‚æˆåŠŸï¼Œå¢åŠ è®¡æ•°
            self.request_count += 1

            if df is None or df.empty:
                logger.error(f"  {trade_date} æœ€ç»ˆé‡è¯•ä»æœªè·å–åˆ°æ•°æ®ï¼Œä»»åŠ¡å°†ç»“æŸ")
                return None

            # è½¬æ¢æ•°æ®æ ¼å¼
            all_daily_data = []
            for _, row in df.iterrows():
                daily_item = {
                    "stockCode": row["ts_code"],
                    "tradeDate": f"{row['trade_date'][:4]}-{row['trade_date'][4:6]}-{row['trade_date'][6:8]}",
                    "openPrice": float(row["open"]) if pd.notna(row["open"]) else None,
                    "highPrice": float(row["high"]) if pd.notna(row["high"]) else None,
                    "lowPrice": float(row["low"]) if pd.notna(row["low"]) else None,
                    "closePrice": float(row["close"]) if pd.notna(row["close"]) else None,
                    "preClose": float(row["pre_close"]) if pd.notna(row["pre_close"]) else None,
                    "changeAmount": float(row["change"]) if pd.notna(row["change"]) else None,
                    "pctChange": float(row["pct_chg"]) if pd.notna(row["pct_chg"]) else None,
                    "volume": float(row["vol"]) if pd.notna(row["vol"]) else None,
                    "amount": float(row["amount"]) if pd.notna(row["amount"]) else None
                }
                all_daily_data.append(daily_item)

            logger.info(f"  æœ€ç»ˆé‡è¯•æˆåŠŸï¼Œä»Tushareè·å–åˆ° {len(all_daily_data)} æ¡è®°å½•")
            return all_daily_data

        except Exception as e:
            logger.error(f"  {trade_date} æœ€ç»ˆé‡è¯•å¤±è´¥: {str(e)}ï¼Œä»»åŠ¡å°†ç»“æŸ")
            return None

    async def _check_rate_limit(self):
        """
        æ£€æŸ¥å¹¶æ§åˆ¶APIè°ƒç”¨é¢‘ç‡
        ä»ç¬¬ä¸€æ¬¡è¯·æ±‚Tushareå¼€å§‹è®¡æ—¶ï¼Œæ¯åˆ†é’Ÿæœ€å¤š45æ¬¡è¯·æ±‚
        """
        current_time = time.time()

        # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡è¯·æ±‚ï¼Œè®°å½•å¼€å§‹æ—¶é—´
        if self.minute_start_time is None:
            self.minute_start_time = current_time
            logger.info(f"â±ï¸  å¼€å§‹è®¡æ—¶ï¼Œæ¯åˆ†é’Ÿæœ€å¤š {self.request_limit} æ¬¡è¯·æ±‚")
            return

        # è®¡ç®—ä»ç¬¬ä¸€æ¬¡è¯·æ±‚åˆ°ç°åœ¨ç»è¿‡çš„æ—¶é—´
        elapsed = current_time - self.minute_start_time

        # å¦‚æœå·²ç»è¶…è¿‡1åˆ†é’Ÿï¼Œé‡ç½®è®¡æ•°å’Œå¼€å§‹æ—¶é—´
        if elapsed >= 60:
            self.request_count = 0
            self.minute_start_time = current_time
            logger.info(f"â±ï¸  æ–°çš„ä¸€åˆ†é’Ÿå¼€å§‹ï¼Œé‡ç½®è®¡æ•°å™¨")
            return

        # å¦‚æœè¾¾åˆ°é™åˆ¶ï¼Œç­‰å¾…åˆ°ä¸‹ä¸€åˆ†é’Ÿ
        if self.request_count >= self.request_limit:
            wait_time = 60 - elapsed
            if wait_time > 0:
                logger.info(f"â¸ï¸  å·²è¾¾åˆ°é¢‘ç‡é™åˆ¶({self.request_limit}æ¬¡/åˆ†é’Ÿ)ï¼Œç­‰å¾… {wait_time:.1f} ç§’åˆ°ä¸‹ä¸€åˆ†é’Ÿ...")
                await asyncio.sleep(wait_time)
            # é‡ç½®è®¡æ•°å’Œæ—¶é—´
            self.request_count = 0
            self.minute_start_time = time.time()
            logger.info(f"â±ï¸  æ–°çš„ä¸€åˆ†é’Ÿå¼€å§‹ï¼Œé‡ç½®è®¡æ•°å™¨")

    async def _save_daily_data(self, daily_data: List[Dict]) -> bool:
        """
        æ‰¹é‡ä¿å­˜æ—¥çº¿æ•°æ®åˆ°æ•°æ®åº“

        Args:
            daily_data: æ—¥çº¿æ•°æ®åˆ—è¡¨

        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        if not daily_data:
            return False

        try:
            async with httpx.AsyncClient(timeout=None) as client:
                response = await client.post(
                    f"{self.api_base_url}/stock-daily/batch",
                    json=daily_data,
                    headers=self.headers
                )
                response.raise_for_status()

                result = response.json()
                if result.get("code") == 200:
                    return True
                else:
                    logger.error(f"ä¿å­˜æ—¥çº¿æ•°æ®å¤±è´¥: {result.get('message')}")
                    return False

        except Exception as e:
            logger.error(f"ä¿å­˜æ—¥çº¿æ•°æ®å¤±è´¥: {str(e)}")
            return False
